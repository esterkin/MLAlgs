#! /usr/bin/python
'''
Created on June 1, 2014

@author: Edward Sterkin
@email:  esterkin@umail.ucsb.edu

'''
import sys
import os
from sys import argv
import numpy as np
from random import randrange
from math import sqrt


'''

Following functions by Karthik Puthraya (karthik@puthraya.com):

add_vectors(), multiply_scalar_vector()
dot_product() l2_norm() 
train_classifier() - slightly modified
test_classifier() - moderately modified 


'''

verbose = False

def add_vectors(a, b):
    '''Add vectors a and b '''
    assert len(a) == len(b)
    return [a[i]+b[i] for i in range(len(a))]

def multiply_scalar_vector(alpha, vec):
    '''Multiply vector vec with scalar alpha '''
    return [alpha*f for f in vec]

def dot_product(a, b):
    '''Dot product of two vectors '''
    assert len(a) == len(b)
    return sum([a[i]*b[i] for i in range(len(a))])
    
def l2_norm(vec):
    '''Compute the L2 norm of the vector vec'''
    return sqrt(sum([vec[i]**2 for i in range(len(vec))]))

def train_classifier(filename):
    '''Read a training file and learn the parameters for each class'''

    training_file = open(filename)
    
    # Read the dimensions and the number of training points in each class
    D, nA, nB = map(int, training_file.readline().split())
    centroids = [[0 for _ in range(D)] for __ in range(2)]
    
    i, c = 0, 0 # Line and class counters
    for line in training_file:
        # Ground truth for x
        if i < nA:
        	c = 0   #positive class 
        else:
        	c = 1   #negative class 
               
        x = map(float, line.split())
        assert len(x) == D # Dimensions should match
        
        # Add x to the corresponding classs
        centroids[c] = add_vectors(centroids[c], x)
        i+=1
    training_file.close()
    
    # Number of points in each class should sum to the total number of points
    assert i == nA + nB

    # Compute the centroids of each class    
    centroids[0] = multiply_scalar_vector(1.0/nA, centroids[0])
    centroids[1] = multiply_scalar_vector(1.0/nB, centroids[1])

    # Compute the weights of the discriminant function for each class
    p, n = centroids[0], centroids[1]
    w = add_vectors(p, multiply_scalar_vector(-1, n)) # w = p-n
    t = (l2_norm(p)**2 - l2_norm(n)**2)/2.0 # t = (p^2-n^2)/2
    w.append(t)
    return w



# weightLists - list of weight lists generated by each classifier 

def test_classifier(filename, weightsLists):

	'''Read a test file and compute the expected class for each of the test points.
	Compute various parameters of the classification task and print them 
	'''

	test_file = open(filename)

	# Read the dimensions and the number of training points in each class
	# D - dimensionality of the samples
	# nA - number of samples in true class
	# nB - number of samples in false class 

	D, nA, nB = map(int, test_file.readline().split()) 
    
	actuals = [] #actual test data 
	actualsCopy = [] # to hold copy of test data 
	for line in test_file:
		actuals.append(map(float, line.split()))
		actualsCopy.append(map(float, line.split()))

	test_file.close()

	allPredictions = []
	# print weightsLists 
	# print '\n\n'

	for x in actuals:
		x.append(-1.0)

	bootstrapCount = 0
	for W in weightsLists:
		predictions = []
		z = 0
		if(verbose == True):
			print('Bootstrap sample set:'), bootstrapCount
		for x in actuals:
			assert len(x) == D + 1  # Dimensions should match

			if dot_product(W, x) >= 0:
				predicted_class = 0        #predict true class 	                         
			else:
				predicted_class = 1        #predict false class  			
			predictions.append(predicted_class)

			if(verbose == True):
				sys.stdout.write(str(actualsCopy[z]))
				if(predicted_class == 0):
					sys.stdout.write(' - True\n')
				elif(predicted_class == 1):
					sys.stdout.write(' - False\n')
			z+=1

		if(verbose == True):
			print('\n')
		bootstrapCount = bootstrapCount +1
		allPredictions.append(predictions)

	predictionTuples = zip(*allPredictions)
	# print predictionTuples
	# print '\n\n'

	predictedClasses = []

	count = 0
	#use majority rule to choose prediction
	for atuple in predictionTuples:
		pos_predictions = 0
		neg_predictions = 0
		for prediction in atuple:
			# print 'prediction',prediction
			if prediction == 0:
				pos_predictions = pos_predictions + 1
			elif prediction == 1:
				neg_predictions = neg_predictions + 1

		if pos_predictions > neg_predictions:
			predicted_class = 0
		elif neg_predictions > pos_predictions:
			predicted_class = 1
		else:
			predicted_class = 0
		predictedClasses.append(predicted_class) #add to final array of predicted classes



	# print 'predictedClasses', predictedClasses,'\n\n'


	i = 0   # Line counter
	falsePositives = 0
	falseNegatives = 0
	if(verbose == True):
		sys.stdout.write("Classification:\n")
	for predictedClass in predictedClasses:
		if(verbose == True):
			sys.stdout.write(str(actualsCopy[i]))
			if(predictedClass == 0):
				sys.stdout.write(' - True')
			elif(predictedClass == 1):
				sys.stdout.write(' - False')

		if i < nA:          
			actual_class = 0 # TRUE CLASS 
		else:
			actual_class = 1 # FALSE CLASS 


		if predictedClass == actual_class:
			if(verbose == True):
				sys.stdout.write(" (correct)\n")
		elif predictedClass == 0 and actual_class == 1:
			if(verbose == True):
				sys.stdout.write(" (false positive)\n")
			falsePositives+=1
		elif predictedClass == 1 and actual_class == 0:
			if(verbose == True):
				sys.stdout.write(" (false negative)\n")	
			falseNegatives+=1	
		i = i+1

	if(verbose == True): print('')
	print('Positive examples: '), nA
	print('Negative examples: '), nB
	print('False positives: '),falsePositives
	print('False negatives: '),falseNegatives

   


def get_array(filename):
	datafile = open(filename)
	D, n_true, n_false = map(int, datafile.readline().split())				
	return D, n_true, n_false, np.loadtxt(datafile) 


if __name__ == "__main__":

	if len(argv) == 5 or len(argv) == 6:
		n = 0
		if argv[1] == '-v':
			verbose = True
			n = 1

		nClassifiers = int(argv[n+1]) #T
		nDataPoints = int(argv[n+2])  #size 

		train_D, train_n_true, train_n_false, training_data = get_array(argv[n+3])
		trainRows = train_n_true + train_n_false

		test_D, test_n_true, test_n_false, testing_data = get_array(argv[n+4])
		testRows = test_n_true + test_n_false
		weightVectors = []

		for i in range(nClassifiers):
			tempfilename = 'train' + str(i) + '.txt'
			tempfile = open(tempfilename, 'w+') #approved by Karthik 
			tempnparray = np.zeros([nDataPoints, train_D + 1])
			n_pos = 0 
			n_neg = 0 
			for j in range(nDataPoints):
				classtype = 2 #negative class 
				rand_train_row_index = randrange(trainRows)
				if (rand_train_row_index + 1) <= train_n_true:
					classtype = 1 #positive class 
					n_pos = n_pos + 1
				else:
					n_neg = n_neg + 1
				#temporary add classifier type to training data	(so we can sort it)
				tempnparray[j,:] = np.concatenate([training_data[rand_train_row_index],np.array([classtype])])
			tempnparray = tempnparray[tempnparray[:,train_D].argsort()] # sort by class 
			# print tempnparray
			tempnparray = tempnparray[:,:train_D] # remove sorting column 
			
			#create temp training file (approved by Karthik)
			tempfile.write(str(train_D) + " " + str(n_pos) + " " + str(n_neg) + '\n')
			np.savetxt(tempfile,tempnparray, fmt='%s')	
			tempfile.close()  

			W = train_classifier(tempfilename)
			os.remove(tempfilename)
			weightVectors.append(W)

		#once we have all the weights for each classifier, run them on the test data
		test_classifier(argv[n+4],weightVectors)
		#print  weightVectors


	else: 
		print 'Please input correct command arguments'
